----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 32, 224, 224]          10,400
       BatchNorm2d-2         [-1, 32, 224, 224]              64
            Conv2d-3         [-1, 64, 112, 112]          32,832
       BatchNorm2d-4         [-1, 64, 112, 112]             128
            Conv2d-5          [-1, 128, 56, 56]         131,200
       BatchNorm2d-6          [-1, 128, 56, 56]             256
            Conv2d-7          [-1, 128, 56, 56]         147,584
       BatchNorm2d-8          [-1, 128, 56, 56]             256
            Conv2d-9          [-1, 128, 56, 56]         147,584
      BatchNorm2d-10          [-1, 128, 56, 56]             256
    ResidualBlock-11          [-1, 128, 56, 56]               0
           Conv2d-12          [-1, 128, 56, 56]         147,584
      BatchNorm2d-13          [-1, 128, 56, 56]             256
           Conv2d-14          [-1, 128, 56, 56]         147,584
      BatchNorm2d-15          [-1, 128, 56, 56]             256
    ResidualBlock-16          [-1, 128, 56, 56]               0
           Conv2d-17          [-1, 128, 56, 56]         147,584
      BatchNorm2d-18          [-1, 128, 56, 56]             256
           Conv2d-19          [-1, 128, 56, 56]         147,584
      BatchNorm2d-20          [-1, 128, 56, 56]             256
    ResidualBlock-21          [-1, 128, 56, 56]               0
           Conv2d-22           [-1, 32, 56, 56]           4,128
      BatchNorm2d-23           [-1, 32, 56, 56]              64
           Conv2d-24           [-1, 32, 56, 56]           9,248
      BatchNorm2d-25           [-1, 32, 56, 56]              64
           Conv2d-26           [-1, 32, 56, 56]           4,128
      BatchNorm2d-27           [-1, 32, 56, 56]              64
           Conv2d-28           [-1, 32, 56, 56]           9,248
      BatchNorm2d-29           [-1, 32, 56, 56]              64
           Conv2d-30           [-1, 32, 56, 56]           9,248
      BatchNorm2d-31           [-1, 32, 56, 56]              64
           Conv2d-32           [-1, 16, 56, 56]           2,064
      BatchNorm2d-33           [-1, 16, 56, 56]              32
           Conv2d-34           [-1, 32, 56, 56]           4,640
      BatchNorm2d-35           [-1, 32, 56, 56]              64
           Conv2d-36           [-1, 32, 56, 56]           9,248
      BatchNorm2d-37           [-1, 32, 56, 56]              64
           Conv2d-38           [-1, 64, 56, 56]           8,256
      BatchNorm2d-39           [-1, 64, 56, 56]             128
           Conv2d-40           [-1, 96, 56, 56]          43,104
      BatchNorm2d-41           [-1, 96, 56, 56]             192
           Conv2d-42           [-1, 96, 56, 56]          64,608
      BatchNorm2d-43           [-1, 96, 56, 56]             192
           Conv2d-44           [-1, 32, 56, 56]          27,680
      BatchNorm2d-45           [-1, 32, 56, 56]              64
           Conv2d-46          [-1, 128, 56, 56]          16,512
      BatchNorm2d-47          [-1, 128, 56, 56]             256
           Conv2d-48          [-1, 128, 56, 56]          16,512
      BatchNorm2d-49          [-1, 128, 56, 56]             256
ReceptiveFieldBlock-50          [-1, 128, 56, 56]               0
           Conv2d-51          [-1, 256, 56, 56]         590,080
          Sigmoid-52          [-1, 256, 56, 56]               0
   PixelAttention-53          [-1, 256, 56, 56]               0
AdaptiveAvgPool2d-54            [-1, 256, 1, 1]               0
           Conv2d-55             [-1, 16, 1, 1]           4,096
             ReLU-56             [-1, 16, 1, 1]               0
           Conv2d-57            [-1, 256, 1, 1]           4,096
          Sigmoid-58            [-1, 256, 1, 1]               0
 ChannelAttention-59          [-1, 256, 56, 56]               0
MultiDimensionalAttentionFusion-60          [-1, 256, 56, 56]               0
  ConvTranspose2d-61         [-1, 64, 112, 112]         262,208
      BatchNorm2d-62         [-1, 64, 112, 112]             128
           Conv2d-63        [-1, 128, 112, 112]         147,584
          Sigmoid-64        [-1, 128, 112, 112]               0
   PixelAttention-65        [-1, 128, 112, 112]               0
AdaptiveAvgPool2d-66            [-1, 128, 1, 1]               0
           Conv2d-67              [-1, 8, 1, 1]           1,024
             ReLU-68              [-1, 8, 1, 1]               0
           Conv2d-69            [-1, 128, 1, 1]           1,024
          Sigmoid-70            [-1, 128, 1, 1]               0
 ChannelAttention-71        [-1, 128, 112, 112]               0
MultiDimensionalAttentionFusion-72        [-1, 128, 112, 112]               0
  ConvTranspose2d-73         [-1, 32, 224, 224]          65,568
      BatchNorm2d-74         [-1, 32, 224, 224]              64
          Dropout-75         [-1, 32, 224, 224]               0
           Conv2d-76          [-1, 1, 224, 224]             289
          Dropout-77         [-1, 32, 224, 224]               0
           Conv2d-78          [-1, 1, 224, 224]             289
          Dropout-79         [-1, 32, 224, 224]               0
           Conv2d-80          [-1, 1, 224, 224]             289
          Dropout-81         [-1, 32, 224, 224]               0
           Conv2d-82          [-1, 1, 224, 224]             289
================================================================
Total params: 2,369,140
Trainable params: 2,369,140
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.77
Forward/backward pass size (MB): 308.56
Params size (MB): 9.04
Estimated Total Size (MB): 318.36
----------------------------------------------------------------
